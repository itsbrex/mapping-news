name: Parse RSS Feeds

on:
  schedule:
    # Run every hour
    - cron: "*/30 13-22 * * *"
    - cron: "0 23,0-2,12 * * *"
    - cron: "0 3-11/2 * * *"
  workflow_dispatch: # Allow manual triggering

jobs:
  parse-feeds:
    runs-on: ubuntu-latest
    environment: production

    steps:
      # Step 1: Check out the repository
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: Set up Python with Poetry
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.12.8"
      - name: Install Poetry
        run: |
          pip install poetry

      # Step 3: Restore cache
      - name: Restore cache
        uses: actions/cache@v4
        with:
          path: cache
          key: ${{ runner.os }}-cache-artifacts
          restore-keys: |
            ${{ runner.os }}-cache-artifacts

      # Step 4: Install dependencies
      - name: Install dependencies
        run: poetry install

      # Step 5: Prepare cache directory
      - name: Prepare cache directory
        run: mkdir -p cache

      # Step 6: Run the feed parser script
      - name: Run feed parser script
        run: poetry run python actions/feedParser.py
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GOOGLE_MAPS_API_KEY: ${{ secrets.GOOGLE_MAPS_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_API_KEY: ${{ secrets.SUPABASE_API_KEY }}
          SUPABASE_SER_KEY: ${{ secrets.SUPABASE_SER_KEY }}

      # Step 7: Save cache
      - name: Save cache
        uses: actions/cache@v4
        with:
          path: cache
          key: ${{ runner.os }}-cache-artifacts-${{ github.run_id }}
